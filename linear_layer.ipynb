{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.labels = {'pneumonia': 0, 'covid': 1, 'normal': 2}  # labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        e = torch.stack(item['e'])  # Stack tensors to form a single tensor\n",
    "        # Normalize the tensor between 0 and 1\n",
    "        e_min = e.min()\n",
    "        e_max = e.max()\n",
    "        e = (e - e_min) / (e_max - e_min)\n",
    "        label = self.labels[item['label']]\n",
    "        return e, label\n",
    "\n",
    "# Load your dataset\n",
    "data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    f = open(os.path.join(data_dir, file), 'rb')\n",
    "    data.append(pickle.load(f))\n",
    "dataset = LungDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class LungClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LungClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "input_size = 60\n",
    "num_classes = 3\n",
    "model = LungClassifier(input_size, num_classes).to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/400], Loss: 1.0948, Accuracy: 0.3700\n",
      "Epoch [2/400], Loss: 1.0855, Accuracy: 0.4100\n",
      "Epoch [3/400], Loss: 1.0794, Accuracy: 0.4300\n",
      "Epoch [4/400], Loss: 1.0748, Accuracy: 0.4400\n",
      "Epoch [5/400], Loss: 1.0712, Accuracy: 0.4500\n",
      "Epoch [6/400], Loss: 1.0681, Accuracy: 0.4550\n",
      "Epoch [7/400], Loss: 1.0653, Accuracy: 0.4570\n",
      "Epoch [8/400], Loss: 1.0630, Accuracy: 0.4600\n",
      "Epoch [9/400], Loss: 1.0609, Accuracy: 0.4650\n",
      "Epoch [10/400], Loss: 1.0585, Accuracy: 0.4675\n",
      "Epoch [11/400], Loss: 1.0567, Accuracy: 0.4700\n",
      "Epoch [12/400], Loss: 1.0549, Accuracy: 0.4740\n",
      "Epoch [13/400], Loss: 1.0534, Accuracy: 0.4760\n",
      "Epoch [14/400], Loss: 1.0520, Accuracy: 0.4780\n",
      "Epoch [15/400], Loss: 1.0505, Accuracy: 0.4800\n",
      "Epoch [16/400], Loss: 1.0491, Accuracy: 0.4815\n",
      "Epoch [17/400], Loss: 1.0480, Accuracy: 0.4820\n",
      "Epoch [18/400], Loss: 1.0469, Accuracy: 0.4850\n",
      "Epoch [19/400], Loss: 1.0459, Accuracy: 0.4870\n",
      "Epoch [20/400], Loss: 1.0450, Accuracy: 0.4900\n",
      "Epoch [21/400], Loss: 1.0440, Accuracy: 0.4920\n",
      "Epoch [22/400], Loss: 1.0433, Accuracy: 0.4940\n",
      "Epoch [23/400], Loss: 1.0424, Accuracy: 0.4950\n",
      "Epoch [24/400], Loss: 1.0416, Accuracy: 0.4965\n",
      "Epoch [25/400], Loss: 1.0410, Accuracy: 0.4970\n",
      "Epoch [26/400], Loss: 1.0403, Accuracy: 0.4985\n",
      "Epoch [27/400], Loss: 1.0396, Accuracy: 0.4990\n",
      "Epoch [28/400], Loss: 1.0387, Accuracy: 0.5005\n",
      "Epoch [29/400], Loss: 1.0383, Accuracy: 0.5010\n",
      "Epoch [30/400], Loss: 1.0377, Accuracy: 0.5020\n",
      "Epoch [31/400], Loss: 1.0372, Accuracy: 0.5035\n",
      "Epoch [32/400], Loss: 1.0367, Accuracy: 0.5050\n",
      "Epoch [33/400], Loss: 1.0362, Accuracy: 0.5060\n",
      "Epoch [34/400], Loss: 1.0358, Accuracy: 0.5070\n",
      "Epoch [35/400], Loss: 1.0352, Accuracy: 0.5080\n",
      "Epoch [36/400], Loss: 1.0347, Accuracy: 0.5090\n",
      "Epoch [37/400], Loss: 1.0345, Accuracy: 0.5100\n",
      "Epoch [38/400], Loss: 1.0341, Accuracy: 0.5115\n",
      "Epoch [39/400], Loss: 1.0336, Accuracy: 0.5120\n",
      "Epoch [40/400], Loss: 1.0331, Accuracy: 0.5130\n",
      "Epoch [41/400], Loss: 1.0328, Accuracy: 0.5145\n",
      "Epoch [42/400], Loss: 1.0326, Accuracy: 0.5150\n",
      "Epoch [43/400], Loss: 1.0321, Accuracy: 0.5160\n",
      "Epoch [44/400], Loss: 1.0319, Accuracy: 0.5165\n",
      "Epoch [45/400], Loss: 1.0316, Accuracy: 0.5170\n",
      "Epoch [46/400], Loss: 1.0312, Accuracy: 0.5185\n",
      "Epoch [47/400], Loss: 1.0309, Accuracy: 0.5190\n",
      "Epoch [48/400], Loss: 1.0306, Accuracy: 0.5200\n",
      "Epoch [49/400], Loss: 1.0302, Accuracy: 0.5210\n",
      "Epoch [50/400], Loss: 1.0300, Accuracy: 0.5215\n",
      "Epoch [51/400], Loss: 1.0295, Accuracy: 0.5220\n",
      "Epoch [52/400], Loss: 1.0294, Accuracy: 0.5230\n",
      "Epoch [53/400], Loss: 1.0290, Accuracy: 0.5240\n",
      "Epoch [54/400], Loss: 1.0288, Accuracy: 0.5250\n",
      "Epoch [55/400], Loss: 1.0286, Accuracy: 0.5255\n",
      "Epoch [56/400], Loss: 1.0285, Accuracy: 0.5260\n",
      "Epoch [57/400], Loss: 1.0282, Accuracy: 0.5270\n",
      "Epoch [58/400], Loss: 1.0280, Accuracy: 0.5280\n",
      "Epoch [59/400], Loss: 1.0277, Accuracy: 0.5295\n",
      "Epoch [60/400], Loss: 1.0276, Accuracy: 0.5300\n",
      "Epoch [61/400], Loss: 1.0274, Accuracy: 0.5325\n",
      "Epoch [62/400], Loss: 1.0272, Accuracy: 0.5330\n",
      "Epoch [63/400], Loss: 1.0270, Accuracy: 0.5342\n",
      "Epoch [64/400], Loss: 1.0267, Accuracy: 0.5363\n",
      "Epoch [65/400], Loss: 1.0266, Accuracy: 0.5370\n",
      "Epoch [66/400], Loss: 1.0263, Accuracy: 0.5378\n",
      "Epoch [67/400], Loss: 1.0262, Accuracy: 0.5385\n",
      "Epoch [68/400], Loss: 1.0260, Accuracy: 0.5392\n",
      "Epoch [69/400], Loss: 1.0257, Accuracy: 0.5406\n",
      "Epoch [70/400], Loss: 1.0257, Accuracy: 0.5412\n",
      "Epoch [71/400], Loss: 1.0255, Accuracy: 0.5423\n",
      "Epoch [72/400], Loss: 1.0253, Accuracy: 0.5440\n",
      "Epoch [73/400], Loss: 1.0252, Accuracy: 0.5455\n",
      "Epoch [74/400], Loss: 1.0251, Accuracy: 0.5460\n",
      "Epoch [75/400], Loss: 1.0248, Accuracy: 0.5468\n",
      "Epoch [76/400], Loss: 1.0247, Accuracy: 0.5472\n",
      "Epoch [77/400], Loss: 1.0245, Accuracy: 0.5482\n",
      "Epoch [78/400], Loss: 1.0244, Accuracy: 0.5490\n",
      "Epoch [79/400], Loss: 1.0243, Accuracy: 0.5500\n",
      "Epoch [80/400], Loss: 1.0241, Accuracy: 0.5512\n",
      "Epoch [81/400], Loss: 1.0240, Accuracy: 0.5520\n",
      "Epoch [82/400], Loss: 1.0239, Accuracy: 0.5528\n",
      "Epoch [83/400], Loss: 1.0238, Accuracy: 0.5533\n",
      "Epoch [84/400], Loss: 1.0237, Accuracy: 0.5540\n",
      "Epoch [85/400], Loss: 1.0235, Accuracy: 0.5550\n",
      "Epoch [86/400], Loss: 1.0234, Accuracy: 0.5556\n",
      "Epoch [87/400], Loss: 1.0231, Accuracy: 0.5569\n",
      "Epoch [88/400], Loss: 1.0231, Accuracy: 0.5576\n",
      "Epoch [89/400], Loss: 1.0230, Accuracy: 0.5580\n",
      "Epoch [90/400], Loss: 1.0229, Accuracy: 0.5590\n",
      "Epoch [91/400], Loss: 1.0226, Accuracy: 0.5600\n",
      "Epoch [92/400], Loss: 1.0226, Accuracy: 0.5610\n",
      "Epoch [93/400], Loss: 1.0225, Accuracy: 0.5620\n",
      "Epoch [94/400], Loss: 1.0225, Accuracy: 0.5630\n",
      "Epoch [95/400], Loss: 1.0222, Accuracy: 0.5645\n",
      "Epoch [96/400], Loss: 1.0220, Accuracy: 0.5655\n",
      "Epoch [97/400], Loss: 1.0221, Accuracy: 0.5665\n",
      "Epoch [98/400], Loss: 1.0220, Accuracy: 0.5670\n",
      "Epoch [99/400], Loss: 1.0218, Accuracy: 0.5677\n",
      "Epoch [100/400], Loss: 1.0217, Accuracy: 0.5682\n",
      "Epoch [101/400], Loss: 1.0216, Accuracy: 0.5693\n",
      "Epoch [102/400], Loss: 1.0215, Accuracy: 0.5706\n",
      "Epoch [103/400], Loss: 1.0215, Accuracy: 0.5710\n",
      "Epoch [104/400], Loss: 1.0212, Accuracy: 0.5715\n",
      "Epoch [105/400], Loss: 1.0211, Accuracy: 0.5725\n",
      "Epoch [106/400], Loss: 1.0212, Accuracy: 0.5733\n",
      "Epoch [107/400], Loss: 1.0211, Accuracy: 0.5740\n",
      "Epoch [108/400], Loss: 1.0209, Accuracy: 0.5751\n",
      "Epoch [109/400], Loss: 1.0208, Accuracy: 0.5765\n",
      "Epoch [110/400], Loss: 1.0205, Accuracy: 0.5771\n",
      "Epoch [111/400], Loss: 1.0207, Accuracy: 0.5786\n",
      "Epoch [112/400], Loss: 1.0203, Accuracy: 0.5795\n",
      "Epoch [113/400], Loss: 1.0204, Accuracy: 0.5805\n",
      "Epoch [114/400], Loss: 1.0205, Accuracy: 0.5809\n",
      "Epoch [115/400], Loss: 1.0204, Accuracy: 0.5816\n",
      "Epoch [116/400], Loss: 1.0202, Accuracy: 0.5825\n",
      "Epoch [117/400], Loss: 1.0201, Accuracy: 0.5833\n",
      "Epoch [118/400], Loss: 1.0200, Accuracy: 0.5840\n",
      "Epoch [119/400], Loss: 1.0199, Accuracy: 0.5845\n",
      "Epoch [120/400], Loss: 1.0198, Accuracy: 0.5850\n",
      "Epoch [121/400], Loss: 1.0197, Accuracy: 0.5856\n",
      "Epoch [122/400], Loss: 1.0197, Accuracy: 0.5861\n",
      "Epoch [123/400], Loss: 1.0196, Accuracy: 0.5867\n",
      "Epoch [124/400], Loss: 1.0195, Accuracy: 0.5871\n",
      "Epoch [125/400], Loss: 1.0192, Accuracy: 0.5876\n",
      "Epoch [126/400], Loss: 1.0193, Accuracy: 0.5879\n",
      "Epoch [127/400], Loss: 1.0193, Accuracy: 0.5885\n",
      "Epoch [128/400], Loss: 1.0193, Accuracy: 0.5891\n",
      "Epoch [129/400], Loss: 1.0191, Accuracy: 0.5896\n",
      "Epoch [130/400], Loss: 1.0190, Accuracy: 0.5900\n",
      "Epoch [131/400], Loss: 1.0189, Accuracy: 0.5905\n",
      "Epoch [132/400], Loss: 1.0189, Accuracy: 0.5910\n",
      "Epoch [133/400], Loss: 1.0188, Accuracy: 0.5916\n",
      "Epoch [134/400], Loss: 1.0188, Accuracy: 0.5922\n",
      "Epoch [135/400], Loss: 1.0187, Accuracy: 0.5927\n",
      "Epoch [136/400], Loss: 1.0185, Accuracy: 0.5930\n",
      "Epoch [137/400], Loss: 1.0185, Accuracy: 0.5933\n",
      "Epoch [138/400], Loss: 1.0186, Accuracy: 0.5940\n",
      "Epoch [139/400], Loss: 1.0185, Accuracy: 0.5947\n",
      "Epoch [140/400], Loss: 1.0183, Accuracy: 0.5953\n",
      "Epoch [141/400], Loss: 1.0183, Accuracy: 0.5960\n",
      "Epoch [142/400], Loss: 1.0182, Accuracy: 0.5965\n",
      "Epoch [143/400], Loss: 1.0182, Accuracy: 0.5970\n",
      "Epoch [144/400], Loss: 1.0183, Accuracy: 0.5975\n",
      "Epoch [145/400], Loss: 1.0182, Accuracy: 0.5980\n",
      "Epoch [146/400], Loss: 1.0178, Accuracy: 0.5985\n",
      "Epoch [147/400], Loss: 1.0180, Accuracy: 0.5990\n",
      "Epoch [148/400], Loss: 1.0179, Accuracy: 0.5993\n",
      "Epoch [149/400], Loss: 1.0178, Accuracy: 0.5997\n",
      "Epoch [150/400], Loss: 1.0180, Accuracy: 0.6000\n",
      "Epoch [151/400], Loss: 1.0177, Accuracy: 0.6003\n",
      "Epoch [152/400], Loss: 1.0175, Accuracy: 0.6005\n",
      "Epoch [153/400], Loss: 1.0176, Accuracy: 0.6008\n",
      "Epoch [154/400], Loss: 1.0174, Accuracy: 0.6011\n",
      "Epoch [155/400], Loss: 1.0174, Accuracy: 0.6015\n",
      "Epoch [156/400], Loss: 1.0174, Accuracy: 0.6018\n",
      "Epoch [157/400], Loss: 1.0173, Accuracy: 0.6021\n",
      "Epoch [158/400], Loss: 1.0173, Accuracy: 0.6025\n",
      "Epoch [159/400], Loss: 1.0171, Accuracy: 0.6028\n",
      "Epoch [160/400], Loss: 1.0171, Accuracy: 0.6030\n",
      "Epoch [161/400], Loss: 1.0171, Accuracy: 0.6035\n",
      "Epoch [162/400], Loss: 1.0170, Accuracy: 0.6040\n",
      "Epoch [163/400], Loss: 1.0169, Accuracy: 0.6045\n",
      "Epoch [164/400], Loss: 1.0169, Accuracy: 0.6048\n",
      "Epoch [165/400], Loss: 1.0169, Accuracy: 0.6050\n",
      "Epoch [166/400], Loss: 1.0169, Accuracy: 0.6054\n",
      "Epoch [167/400], Loss: 1.0165, Accuracy: 0.6057\n",
      "Epoch [168/400], Loss: 1.0167, Accuracy: 0.6060\n",
      "Epoch [169/400], Loss: 1.0167, Accuracy: 0.6065\n",
      "Epoch [170/400], Loss: 1.0167, Accuracy: 0.6068\n",
      "Epoch [171/400], Loss: 1.0166, Accuracy: 0.6070\n",
      "Epoch [172/400], Loss: 1.0164, Accuracy: 0.6073\n",
      "Epoch [173/400], Loss: 1.0165, Accuracy: 0.6075\n",
      "Epoch [174/400], Loss: 1.0164, Accuracy: 0.6076\n",
      "Epoch [175/400], Loss: 1.0165, Accuracy: 0.6078\n",
      "Epoch [176/400], Loss: 1.0162, Accuracy: 0.6085\n",
      "Epoch [177/400], Loss: 1.0162, Accuracy: 0.6090\n",
      "Epoch [178/400], Loss: 1.0162, Accuracy: 0.6095\n",
      "Epoch [179/400], Loss: 1.0161, Accuracy: 0.6100\n",
      "Epoch [180/400], Loss: 1.0161, Accuracy: 0.6105\n",
      "Epoch [181/400], Loss: 1.0158, Accuracy: 0.6112\n",
      "Epoch [182/400], Loss: 1.0160, Accuracy: 0.6117\n",
      "Epoch [183/400], Loss: 1.0160, Accuracy: 0.6123\n",
      "Epoch [184/400], Loss: 1.0159, Accuracy: 0.6129\n",
      "Epoch [185/400], Loss: 1.0158, Accuracy: 0.6133\n",
      "Epoch [186/400], Loss: 1.0158, Accuracy: 0.6140\n",
      "Epoch [187/400], Loss: 1.0158, Accuracy: 0.6144\n",
      "Epoch [188/400], Loss: 1.0157, Accuracy: 0.6150\n",
      "Epoch [189/400], Loss: 1.0157, Accuracy: 0.6156\n",
      "Epoch [190/400], Loss: 1.0156, Accuracy: 0.6160\n",
      "Epoch [191/400], Loss: 1.0156, Accuracy: 0.6165\n",
      "Epoch [192/400], Loss: 1.0156, Accuracy: 0.6170\n",
      "Epoch [193/400], Loss: 1.0156, Accuracy: 0.6176\n",
      "Epoch [194/400], Loss: 1.0155, Accuracy: 0.6180\n",
      "Epoch [195/400], Loss: 1.0153, Accuracy: 0.6186\n",
      "Epoch [196/400], Loss: 1.0153, Accuracy: 0.6190\n",
      "Epoch [197/400], Loss: 1.0154, Accuracy: 0.6195\n",
      "Epoch [198/400], Loss: 1.0152, Accuracy: 0.6201\n",
      "Epoch [199/400], Loss: 1.0151, Accuracy: 0.6206\n",
      "Epoch [200/400], Loss: 1.0151, Accuracy: 0.6211\n",
      "Epoch [201/400], Loss: 0.9990, Accuracy: 0.6219\n",
      "Epoch [202/400], Loss: 0.9948, Accuracy: 0.6232\n",
      "Epoch [203/400], Loss: 0.9827, Accuracy: 0.6245\n",
      "Epoch [204/400], Loss: 0.9732, Accuracy: 0.6262\n",
      "Epoch [205/400], Loss: 0.9605, Accuracy: 0.6281\n",
      "Epoch [206/400], Loss: 0.9553, Accuracy: 0.6299\n",
      "Epoch [207/400], Loss: 0.9454, Accuracy: 0.6310\n",
      "Epoch [208/400], Loss: 0.9331, Accuracy: 0.6322\n",
      "Epoch [209/400], Loss: 0.9279, Accuracy: 0.6340\n",
      "Epoch [210/400], Loss: 0.9212, Accuracy: 0.6356\n",
      "Epoch [211/400], Loss: 0.9125, Accuracy: 0.6372\n",
      "Epoch [212/400], Loss: 0.9011, Accuracy: 0.6390\n",
      "Epoch [213/400], Loss: 0.8943, Accuracy: 0.6407\n",
      "Epoch [214/400], Loss: 0.8825, Accuracy: 0.6425\n",
      "Epoch [215/400], Loss: 0.8766, Accuracy: 0.6440\n",
      "Epoch [216/400], Loss: 0.8689, Accuracy: 0.6455\n",
      "Epoch [217/400], Loss: 0.8591, Accuracy: 0.6470\n",
      "Epoch [218/400], Loss: 0.8512, Accuracy: 0.6489\n",
      "Epoch [219/400], Loss: 0.8433, Accuracy: 0.6505\n",
      "Epoch [220/400], Loss: 0.8361, Accuracy: 0.6520\n",
      "Epoch [221/400], Loss: 0.8279, Accuracy: 0.6536\n",
      "Epoch [222/400], Loss: 0.8207, Accuracy: 0.6552\n",
      "Epoch [223/400], Loss: 0.8131, Accuracy: 0.6565\n",
      "Epoch [224/400], Loss: 0.8058, Accuracy: 0.6579\n",
      "Epoch [225/400], Loss: 0.7990, Accuracy: 0.6595\n",
      "Epoch [226/400], Loss: 0.7920, Accuracy: 0.6610\n",
      "Epoch [227/400], Loss: 0.7851, Accuracy: 0.6625\n",
      "Epoch [228/400], Loss: 0.7779, Accuracy: 0.6640\n",
      "Epoch [229/400], Loss: 0.7717, Accuracy: 0.6655\n",
      "Epoch [230/400], Loss: 0.7649, Accuracy: 0.6672\n",
      "Epoch [231/400], Loss: 0.7584, Accuracy: 0.6688\n",
      "Epoch [232/400], Loss: 0.7518, Accuracy: 0.6701\n",
      "Epoch [233/400], Loss: 0.7454, Accuracy: 0.6716\n",
      "Epoch [234/400], Loss: 0.7390, Accuracy: 0.6730\n",
      "Epoch [235/400], Loss: 0.7317, Accuracy: 0.6745\n",
      "Epoch [236/400], Loss: 0.7253, Accuracy: 0.6759\n",
      "Epoch [237/400], Loss: 0.7189, Accuracy: 0.6770\n",
      "Epoch [238/400], Loss: 0.7128, Accuracy: 0.6785\n",
      "Epoch [239/400], Loss: 0.7061, Accuracy: 0.6800\n",
      "Epoch [240/400], Loss: 0.7000, Accuracy: 0.6815\n",
      "Epoch [241/400], Loss: 0.6936, Accuracy: 0.6829\n",
      "Epoch [242/400], Loss: 0.6876, Accuracy: 0.6840\n",
      "Epoch [243/400], Loss: 0.6810, Accuracy: 0.6855\n",
      "Epoch [244/400], Loss: 0.6747, Accuracy: 0.6870\n",
      "Epoch [245/400], Loss: 0.6690, Accuracy: 0.6880\n",
      "Epoch [246/400], Loss: 0.6630, Accuracy: 0.6895\n",
      "Epoch [247/400], Loss: 0.6570, Accuracy: 0.6905\n",
      "Epoch [248/400], Loss: 0.6511, Accuracy: 0.6918\n",
      "Epoch [249/400], Loss: 0.6457, Accuracy: 0.6930\n",
      "Epoch [250/400], Loss: 0.6400, Accuracy: 0.6945\n",
      "Epoch [251/400], Loss: 0.6347, Accuracy: 0.6955\n",
      "Epoch [252/400], Loss: 0.6291, Accuracy: 0.6968\n",
      "Epoch [253/400], Loss: 0.6237, Accuracy: 0.6980\n",
      "Epoch [254/400], Loss: 0.6181, Accuracy: 0.6993\n",
      "Epoch [255/400], Loss: 0.6131, Accuracy: 0.7005\n",
      "Epoch [256/400], Loss: 0.6076, Accuracy: 0.7015\n",
      "Epoch [257/400], Loss: 0.6023, Accuracy: 0.7025\n",
      "Epoch [258/400], Loss: 0.5973, Accuracy: 0.7037\n",
      "Epoch [259/400], Loss: 0.5923, Accuracy: 0.7045\n",
      "Epoch [260/400], Loss: 0.5869, Accuracy: 0.7056\n",
      "Epoch [261/400], Loss: 0.5819, Accuracy: 0.7066\n",
      "Epoch [262/400], Loss: 0.5770, Accuracy: 0.7078\n",
      "Epoch [263/400], Loss: 0.5721, Accuracy: 0.7088\n",
      "Epoch [264/400], Loss: 0.5674, Accuracy: 0.7099\n",
      "Epoch [265/400], Loss: 0.5622, Accuracy: 0.7109\n",
      "Epoch [266/400], Loss: 0.5577, Accuracy: 0.7118\n",
      "Epoch [267/400], Loss: 0.5530, Accuracy: 0.7128\n",
      "Epoch [268/400], Loss: 0.5479, Accuracy: 0.7141\n",
      "Epoch [269/400], Loss: 0.5430, Accuracy: 0.7152\n",
      "Epoch [270/400], Loss: 0.5383, Accuracy: 0.7163\n",
      "Epoch [271/400], Loss: 0.5340, Accuracy: 0.7176\n",
      "Epoch [272/400], Loss: 0.5291, Accuracy: 0.7186\n",
      "Epoch [273/400], Loss: 0.5245, Accuracy: 0.7197\n",
      "Epoch [274/400], Loss: 0.5199, Accuracy: 0.7206\n",
      "Epoch [275/400], Loss: 0.5153, Accuracy: 0.7218\n",
      "Epoch [276/400], Loss: 0.5107, Accuracy: 0.7227\n",
      "Epoch [277/400], Loss: 0.5065, Accuracy: 0.7235\n",
      "Epoch [278/400], Loss: 0.5021, Accuracy: 0.7245\n",
      "Epoch [279/400], Loss: 0.4976, Accuracy: 0.7256\n",
      "Epoch [280/400], Loss: 0.4933, Accuracy: 0.7268\n",
      "Epoch [281/400], Loss: 0.4889, Accuracy: 0.7278\n",
      "Epoch [282/400], Loss: 0.4847, Accuracy: 0.7286\n",
      "Epoch [283/400], Loss: 0.4805, Accuracy: 0.7295\n",
      "Epoch [284/400], Loss: 0.4763, Accuracy: 0.7306\n",
      "Epoch [285/400], Loss: 0.4723, Accuracy: 0.7316\n",
      "Epoch [286/400], Loss: 0.4682, Accuracy: 0.7325\n",
      "Epoch [287/400], Loss: 0.4641, Accuracy: 0.7335\n",
      "Epoch [288/400], Loss: 0.4603, Accuracy: 0.7345\n",
      "Epoch [289/400], Loss: 0.4564, Accuracy: 0.7356\n",
      "Epoch [290/400], Loss: 0.4525, Accuracy: 0.7366\n",
      "Epoch [291/400], Loss: 0.4487, Accuracy: 0.7376\n",
      "Epoch [292/400], Loss: 0.4449, Accuracy: 0.7387\n",
      "Epoch [293/400], Loss: 0.4412, Accuracy: 0.7398\n",
      "Epoch [294/400], Loss: 0.4376, Accuracy: 0.7408\n",
      "Epoch [295/400], Loss: 0.4339, Accuracy: 0.7418\n",
      "Epoch [296/400], Loss: 0.4302, Accuracy: 0.7429\n",
      "Epoch [297/400], Loss: 0.4266, Accuracy: 0.7440\n",
      "Epoch [298/400], Loss: 0.4230, Accuracy: 0.7451\n",
      "Epoch [299/400], Loss: 0.4294, Accuracy: 0.7461\n",
      "Epoch [300/400], Loss: 0.4259, Accuracy: 0.7473\n",
      "Epoch [301/400], Loss: 0.4225, Accuracy: 0.7495\n",
      "Epoch [302/400], Loss: 0.4201, Accuracy: 0.7507\n",
      "Epoch [303/400], Loss: 0.4180, Accuracy: 0.7521\n",
      "Epoch [304/400], Loss: 0.4158, Accuracy: 0.7530\n",
      "Epoch [305/400], Loss: 0.4137, Accuracy: 0.7545\n",
      "Epoch [306/400], Loss: 0.4115, Accuracy: 0.7556\n",
      "Epoch [307/400], Loss: 0.4093, Accuracy: 0.7569\n",
      "Epoch [308/400], Loss: 0.4078, Accuracy: 0.7582\n",
      "Epoch [309/400], Loss: 0.4059, Accuracy: 0.7595\n",
      "Epoch [310/400], Loss: 0.4039, Accuracy: 0.7607\n",
      "Epoch [311/400], Loss: 0.4018, Accuracy: 0.7622\n",
      "Epoch [312/400], Loss: 0.3998, Accuracy: 0.7635\n",
      "Epoch [313/400], Loss: 0.3982, Accuracy: 0.7648\n",
      "Epoch [314/400], Loss: 0.3964, Accuracy: 0.7657\n",
      "Epoch [315/400], Loss: 0.3946, Accuracy: 0.7671\n",
      "Epoch [316/400], Loss: 0.3929, Accuracy: 0.7685\n",
      "Epoch [317/400], Loss: 0.3911, Accuracy: 0.7695\n",
      "Epoch [318/400], Loss: 0.3892, Accuracy: 0.7707\n",
      "Epoch [319/400], Loss: 0.3878, Accuracy: 0.7718\n",
      "Epoch [320/400], Loss: 0.3860, Accuracy: 0.7729\n",
      "Epoch [321/400], Loss: 0.3844, Accuracy: 0.7739\n",
      "Epoch [322/400], Loss: 0.3829, Accuracy: 0.7750\n",
      "Epoch [323/400], Loss: 0.3812, Accuracy: 0.7761\n",
      "Epoch [324/400], Loss: 0.3798, Accuracy: 0.7775\n",
      "Epoch [325/400], Loss: 0.3782, Accuracy: 0.7786\n",
      "Epoch [326/400], Loss: 0.3765, Accuracy: 0.7797\n",
      "Epoch [327/400], Loss: 0.3751, Accuracy: 0.7809\n",
      "Epoch [328/400], Loss: 0.3735, Accuracy: 0.7820\n",
      "Epoch [329/400], Loss: 0.3720, Accuracy: 0.7830\n",
      "Epoch [330/400], Loss: 0.3705, Accuracy: 0.7841\n",
      "Epoch [331/400], Loss: 0.3690, Accuracy: 0.7852\n",
      "Epoch [332/400], Loss: 0.3676, Accuracy: 0.7863\n",
      "Epoch [333/400], Loss: 0.3662, Accuracy: 0.7875\n",
      "Epoch [334/400], Loss: 0.3648, Accuracy: 0.7887\n",
      "Epoch [335/400], Loss: 0.3635, Accuracy: 0.7897\n",
      "Epoch [336/400], Loss: 0.3620, Accuracy: 0.7910\n",
      "Epoch [337/400], Loss: 0.3607, Accuracy: 0.7921\n",
      "Epoch [338/400], Loss: 0.3593, Accuracy: 0.7931\n",
      "Epoch [339/400], Loss: 0.3580, Accuracy: 0.7942\n",
      "Epoch [340/400], Loss: 0.3567, Accuracy: 0.7951\n",
      "Epoch [341/400], Loss: 0.3554, Accuracy: 0.7963\n",
      "Epoch [342/400], Loss: 0.3541, Accuracy: 0.7972\n",
      "Epoch [343/400], Loss: 0.3529, Accuracy: 0.7982\n",
      "Epoch [344/400], Loss: 0.3517, Accuracy: 0.7991\n",
      "Epoch [345/400], Loss: 0.3505, Accuracy: 0.8001\n",
      "Epoch [346/400], Loss: 0.3492, Accuracy: 0.8013\n",
      "Epoch [347/400], Loss: 0.3480, Accuracy: 0.8022\n",
      "Epoch [348/400], Loss: 0.3468, Accuracy: 0.8032\n",
      "Epoch [349/400], Loss: 0.3457, Accuracy: 0.8041\n",
      "Epoch [350/400], Loss: 0.3445, Accuracy: 0.8052\n",
      "Epoch [351/400], Loss: 0.3434, Accuracy: 0.8061\n",
      "Epoch [352/400], Loss: 0.3422, Accuracy: 0.8071\n",
      "Epoch [353/400], Loss: 0.3411, Accuracy: 0.8082\n",
      "Epoch [354/400], Loss: 0.3400, Accuracy: 0.8091\n",
      "Epoch [355/400], Loss: 0.3389, Accuracy: 0.8101\n",
      "Epoch [356/400], Loss: 0.3377, Accuracy: 0.8111\n",
      "Epoch [357/400], Loss: 0.3366, Accuracy: 0.8120\n",
      "Epoch [358/400], Loss: 0.3355, Accuracy: 0.8131\n",
      "Epoch [359/400], Loss: 0.3344, Accuracy: 0.8140\n",
      "Epoch [360/400], Loss: 0.3334, Accuracy: 0.8149\n",
      "Epoch [361/400], Loss: 0.3323, Accuracy: 0.8158\n",
      "Epoch [362/400], Loss: 0.3313, Accuracy: 0.8168\n",
      "Epoch [363/400], Loss: 0.3302, Accuracy: 0.8178\n",
      "Epoch [364/400], Loss: 0.3292, Accuracy: 0.8188\n",
      "Epoch [365/400], Loss: 0.3282, Accuracy: 0.8199\n",
      "Epoch [366/400], Loss: 0.3272, Accuracy: 0.8208\n",
      "Epoch [367/400], Loss: 0.3262, Accuracy: 0.8217\n",
      "Epoch [368/400], Loss: 0.3252, Accuracy: 0.8226\n",
      "Epoch [369/400], Loss: 0.3242, Accuracy: 0.8236\n",
      "Epoch [370/400], Loss: 0.3232, Accuracy: 0.8245\n",
      "Epoch [371/400], Loss: 0.3223, Accuracy: 0.8253\n",
      "Epoch [372/400], Loss: 0.3213, Accuracy: 0.8264\n",
      "Epoch [373/400], Loss: 0.3203, Accuracy: 0.8273\n",
      "Epoch [374/400], Loss: 0.3194, Accuracy: 0.8279\n",
      "Epoch [375/400], Loss: 0.3185, Accuracy: 0.8288\n",
      "Epoch [376/400], Loss: 0.3176, Accuracy: 0.8297\n",
      "Epoch [377/400], Loss: 0.3167, Accuracy: 0.8307\n",
      "Epoch [378/400], Loss: 0.3158, Accuracy: 0.8317\n",
      "Epoch [379/400], Loss: 0.3150, Accuracy: 0.8325\n",
      "Epoch [380/400], Loss: 0.3141, Accuracy: 0.8333\n",
      "Epoch [381/400], Loss: 0.3132, Accuracy: 0.8340\n",
      "Epoch [382/400], Loss: 0.3123, Accuracy: 0.8348\n",
      "Epoch [383/400], Loss: 0.3115, Accuracy: 0.8354\n",
      "Epoch [384/400], Loss: 0.3107, Accuracy: 0.8362\n",
      "Epoch [385/400], Loss: 0.3099, Accuracy: 0.8369\n",
      "Epoch [386/400], Loss: 0.3091, Accuracy: 0.8376\n",
      "Epoch [387/400], Loss: 0.3083, Accuracy: 0.8382\n",
      "Epoch [388/400], Loss: 0.3075, Accuracy: 0.8389\n",
      "Epoch [389/400], Loss: 0.3067, Accuracy: 0.8396\n",
      "Epoch [390/400], Loss: 0.3060, Accuracy: 0.8402\n",
      "Epoch [391/400], Loss: 0.3052, Accuracy: 0.8408\n",
      "Epoch [392/400], Loss: 0.3045, Accuracy: 0.8413\n",
      "Epoch [393/400], Loss: 0.3037, Accuracy: 0.8418\n",
      "Epoch [394/400], Loss: 0.3030, Accuracy: 0.8423\n",
      "Epoch [395/400], Loss: 0.3023, Accuracy: 0.8428\n",
      "Epoch [396/400], Loss: 0.3016, Accuracy: 0.8434\n",
      "Epoch [397/400], Loss: 0.3009, Accuracy: 0.8438\n",
      "Epoch [398/400], Loss: 0.3002, Accuracy: 0.8443\n",
      "Epoch [399/400], Loss: 0.2995, Accuracy: 0.8448\n",
      "Epoch [400/400], Loss: 0.2988, Accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 400  \n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for e, labels in dataloader:\n",
    "        e, labels = e.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(e)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Collect predictions and labels for accuracy calculation\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "    scheduler.step(epoch_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.fc.weight.data.cpu()  \n",
    "torch.save(weights, 'learned_weights.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
